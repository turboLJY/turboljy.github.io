<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html manifest="welcome.manifest">
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta content="yes" name="apple-mobile-web-app-capable">
  <meta content="black" name="apple-mobile-web-app-status-bar-style">
  <meta content="telephone=no" name="format-detection">
  <meta name="author" content="Junyi Li">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #07889b; /*#1772d0;*/
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #e37222; /*#f7b733;*/ /*f09228;*/
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 15px; /*14*/
    }
    strong {
    font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 15px; /*14*/
    }
    heading {
    font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 22px;
    color: #e37222; /*#fc4a1a;*/
    }
    heading2 {
    font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 18px;
    }
    papertitle {
    font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 15px; /*14*/
    font-weight: 700;
    }
    name {
    font-family: "TeXGyrePagella", "Palatino Linotype", "Book Antiqua", Palatino, serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 42px;
    }
    li:not(:last-child) {
        margin-bottom: 5px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link href="https://tuchuang-1258543525.cos.ap-beijing.myqcloud.com/20180614_161325021_iOS.jpg" rel="Shortcut Icon" type="image/x-icon">
  <title>Junyi Li (李军毅)</title>

  <link href="./stylesheets/main.css" rel="stylesheet" type="text/css">
  <style id="dark-reader-style" type="text/css">@media screen {

/* Leading rule */
/*html {
  -webkit-filter: brightness(100%) contrast(100%) grayscale(20%) sepia(10%) !important;
}*/

/* Text contrast */
html {
  text-shadow: 0 0 0 !important;
}

/* Full screen */
*:-webkit-full-screen, *:-webkit-full-screen * {
  -webkit-filter: none !important;
}

/* Page background */
html {
  background: rgb(255,255,255) !important;
}

}</style>

<script type="text/javascript">
   function visibility_on(id) {
        var e = document.getElementById(id+"_text");
        if(e.style.display == 'none')
            e.style.display = 'block';
        var e = document.getElementById(id+"_img");
        if(e.style.display == 'none')
            e.style.display = 'block';
   }
   function visibility_off(id) {
        var e = document.getElementById(id+"_text");
        if(e.style.display == 'block')
            e.style.display = 'none';
        var e = document.getElementById(id+"_img");
        if(e.style.display == 'block')
            e.style.display = 'none';
   }
   function toggle_visibility(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'inline')
          e.style.display = 'block';
       else
          e.style.display = 'inline';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'inline')
          e.style.display = 'block';
       else
          e.style.display = 'inline';
   }
   function toggle_vis(id) {
       var e = document.getElementById(id);
       if (e.style.display == 'none')
           e.style.display = 'inline';
       else
           e.style.display = 'none';
   }
</script>

</head>
</div>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="67%" valign="middle">
        <p align="center">
        <name>Junyi Li (李军毅)</name><br>
        </p>
        <p style="text-align:justify">
		I have a broad interest in natural language processing. My major 
		research interests lies in the area of Natural Language Generation, especially based on pretrained language models.
	<p>
	<p style="text-align:justify">
		Currently, I am a Ph.D. student from <a href="http://ai.ruc.edu.cn/english/index.htm">GSAI</a>, 
		<a href="https://ruc.edu.cn">Renmin University of China</a>, 
		advised by <a href="http://playbigdata.ruc.edu.cn/batmanfly/">Prof. Wayne Xin Zhao</a>. 
	</p>
	<p style="text-align:justify">
		Meanwhile, I was selected to participate
		in the joint doctral program of <a href="https://ruc.edu.cn">Renmin University of China</a> 
		and <a href="https://www.umontreal.ca/en/">University de Montreal</a>. 
		Starting in 2022, I will study in UdeM for my second Ph.D. degree.
        </p>
	<p>Email: lijunyi at ruc dot edu dot cn / cheneyjunyi at gmail dot com</p>
<!--         <p>
        <i>There is no authority in science. No one can tell whether your research matters or not. Or how much it matters. All you can do is to contribute to human knowledge and hope it will matter. Even if it doesn't, it does. It eliminates an idea.</i><br>
        </p>
		<p align="right">
		<i>-- Rich Sutton</i>
		</p> -->


        <p align="center">
			<a href="./images/resume.pdf" target="_blank">CV</a> &nbsp;/&nbsp;
			<a href="https://scholar.google.com/citations?user=zeWrn-4AAAAJ&hl=zh-CN" target="_blank">Google Scholar</a> &nbsp;/&nbsp;
			<a href="https://github.com/turboLJY" target="_blank"> GitHub </a> &nbsp;/&nbsp;
		    <a href="https://www.zhihu.com/people/li-jun-yi-93" target="_blank">Zhihu</a>
        </p>
        </td>
        <td width="33%">
        <img src="./images/lijunyi.jpg" width="95%">
        </td>
      </tr>
  </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>

        <tr><td>
            <heading>Zhihu Posts</heading>
            <ul>
	      <li> <a href="https://zhuanlan.zhihu.com/p/353972216" target="_blank">Knowledge-Enhanced Text Generation: 知识增强的文本生成研究进展</a></li>
              <li> <a href="https://zhuanlan.zhihu.com/p/69069509" target="_blank">ACL 2019 | 渐入佳境，基于主题感知的Coarse-to-Fine机制的在线评论生成</a></li>
			  <li> <a href="https://zhuanlan.zhihu.com/p/36880287" target="_blank">GAN+文本生成：让文本以假乱真</a></li>
			  
              <li> <a href="javascript:toggle_vis('zhihu-blogs')" style="color:black">show more</a> </li>
				  <div id="zhihu-blogs" style="display:none"> 
		   		  <li> <a href="https://zhuanlan.zhihu.com/p/47949269" target="_blank">开放域下的对话系统</a></li>
			          <li> <a href="https://zhuanlan.zhihu.com/p/61702784" target="_blank">引入知识库生成故事结尾</a></li>
				  <li> <a href="https://zhuanlan.zhihu.com/p/35997048" target="_blank">AAAI2018会议中的应答生成</a></li>
				  <li> <a href="https://zhuanlan.zhihu.com/p/32089282" target="_blank">Attention学习笔记</a></li>
				  <li> <a href="https://zhuanlan.zhihu.com/p/29967933" target="_blank">从文本生成看Seq2Seq模型</a></li>
				  <li> <a href="https://zhuanlan.zhihu.com/p/26604113" target="_blank">EMNLP 2014：利用RNN模型生成中国古代诗歌</a></li>
				 </div>
            </ul>
        </td></tr>

        <tr><td width="100%" valign="middle">
            <heading>Publications</heading> <br><br>
		
	    <heading2><i>Preprint</i></heading2><br><br>
		
	      <div onmouseover="document.getElementById('WenLan').style.display = 'block';"onmouseout="document.getElementById('WenLan').style.display='none';">
              <a href="https://arxiv.org/pdf/2103.06561.pdf">
                <papertitle>WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training</papertitle></a><br>
	      <i>Yuqi Huo</i>, <i>Manli Zhang</i>, <i>Guangzhen Liu</i>, <i>Haoyu Lu</i>, <i>Yizhao Gao</i>, <i>Guoxing Yang</i>, <i>Jingyuan Wen</i>, 
		      <i>Heng Zhang</i>, <i>Baogui Xu</i>,
		      <i>Weihao Zheng</i>, <i>Zongzheng Xi</i>, <i>Yueqian Yang</i>, <i>Anwen Hu</i>, <i>Jinming Zhao</i>, <i>Ruichen Li</i>, 
		      <i>Yida Zhao</i>, <i>Liang Zhang</i>,
		      <i>Yuqing Song</i>, <i>Xin Hong</i>, <i>Wanqing Cui</i>, <i>Danyang Hou</i>, <i>Yingyan Li</i>, <i><strong>Junyi Li</strong></i>, 
		      <i>Peiyu Liu</i>, <i>Zheng Gong</i>, 
		      <i>Chuhao Jin</i>, <i>Yuchong Sun</i>, <i>Shizhe Chen</i>, <i>Zhiwu Lu</i>*, <i>Zhicheng Dou</i>, <i>Qin Jin</i>, 
		      <i>Yanyan Lan</i>, <i>Wayne Xin Zhao</i>, 
		      <i>Ruihua Song</i>*, <i>Ji-Rong Wen</i>*<br>
              <a href="https://arxiv.org/pdf/2103.06561.pdf">pdf</a>  /  <a href="">code</a> 
            </div>
              <div id="WenLan" style="display:none;text-align:justify">
              Multi-modal pre-training models have been intensively explored to bridge vision and language in recent years. However, most of them 
		      explicitly model the cross-modal interaction between image-text pairs, by assuming that there exists strong semantic correlation 
		      between the text and image modalities. Since this strong assumption is often invalid in real-world scenarios, we choose to 
		      implicitly model the cross-modal correlation for large-scale multi-modal pre-training, which is the focus of the Chinese 
		      project `WenLan' led by our team. Specifically, with the weak correlation assumption over image-text pairs, we propose a 
		      two-tower pre-training model called BriVL within the cross-modal contrastive learning framework. Unlike OpenAI CLIP that 
		      adopts a simple contrastive learning method, we devise a more advanced algorithm by adapting the latest method MoCo into 
		      the cross-modal scenario. By building a large queue-based dictionary, our BriVL can incorporate more negative samples in 
		      limited GPU resources. We further construct a large Chinese multi-source image-text dataset called RUC-CAS-WenLan for 
		      pre-training our BriVL model. Extensive experiments demonstrate that the pre-trained BriVL model outperforms both UNITER 
		      and OpenAI CLIP on various downstream tasks.
              </div><br>
		
	    <heading2><i>2021</i></heading2><br><br>
		
	    <div onmouseover="document.getElementById('ThreeGAN').style.display = 'block';"onmouseout="document.getElementById('ThreeGAN').style.display='none';">
              <a href="">
                <papertitle>Generating Long and Coherent Text with Multi-Level Generative Adversarial Networks</papertitle></a><br>
              <i>Tianyi Tang</i>,
              <i><strong>Junyi Li</strong></i>,
	      <i>Wayne Xin Zhao</i>*,
	      <i>Ji-Rong Wen</i>
              <br>
	      <em>The 5th APWeb-WAIM International Joint Conference on Web and Big Data (APWeb-WAIM)</em>, 2021<br>
              <a href="">pdf</a>  /  <a href="">code</a> 
            </div>
              <div id="ThreeGAN" style="display:none;text-align:justify">
              	In this paper, we study the task of generating long and coherent text. In the literature, Generative Adversarial Nets (GAN) based methods 
		      have been one of the mainstream approaches to generic text generation. We aim to improve two aspects of GAN-based methods in generic 
		      text generation, namely long sequence optimization and semantic coherence enhancement. For this purpose, we propose a novel Multi-Level 
		      Generative Adversarial Networks (MLGAN) for long and coherent text generation. Our approach explicitly models the text generation 
		      process at three different levels, namely paragraph-, sentence- and word-level generation. At the top two levels, we generate 
		      continuous paragraph vectors and sentence vectors as \emph{semantic sketches} to plan the entire content. While, at the bottom 
		      level we generate discrete word tokens for realizing the sentences. Furthermore, we utilize a Conditional GAN architecture to 
		      enhance the inter-sentence coherence by injecting paragraph vectors for sentence vector generation. Extensive experiments results 
		      have demonstrated the effectiveness of the proposed model.
              </div><br>
		
	    <div onmouseover="document.getElementById('TextBox').style.display = 'block';"onmouseout="document.getElementById('TextBox').style.display='none';">
              <a href="https://arxiv.org/pdf/2101.02046.pdf">
                <papertitle>TextBox: A Unified, Modularized, and Extensible Framework for Text Generation</papertitle></a><br>
              <i><strong>Junyi Li</strong></i>&dagger;,
              <i>Tianyi Tang</i>&dagger;,
	      <i>Gaole He</i>,
	      <i>Jinhao Jiang</i>,
		<i>Xiaoxuan Hu</i>,
		 <i>Puzhao Xie</i>,
		 <i>Zhipeng Chen</i>, 
		 <i>Zhuohao Yu</i>,
              <i>Wayne Xin Zhao</i>*,
	      <i>Ji-Rong Wen</i>
              <br>
	      <em>The 59th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2021, System Demonstration <br>
              <a href="https://arxiv.org/pdf/2101.02046.pdf">pdf</a>  /  <a href="https://github.com/RUCAIBox/TextBox">code</a> 
            </div>
              <div id="TextBox" style="display:none;text-align:justify">
              We release an open library, called TextBox, which provides a unified, modularized, and extensible text generation framework. TextBox aims 
		      to support a broad set of text generation tasks and models. In TextBox, we implements several text generation models on benchmark 
		      datasets, covering the categories of VAE, GAN, pre-trained language models, etc. Meanwhile, our library maintains sufficient 
		      modularity and extensibility by properly decomposing the model architecture, inference, learning process into highly reusable modules, 
		      which allows easily incorporating new models into our framework. It is specially suitable for researchers and practitioners to 
		      efficiently reproduce baseline models and develop new models. TextBox is implemented based on PyTorch, and released under 
		      Apache License 2.0 at the link https://github.com/RUCAIBox/TextBox.
              </div><br>
		
	    <div onmouseover="document.getElementById('KG-to-Text').style.display = 'block';"onmouseout="document.getElementById('KG-to-Text').style.display='none';">
              <a href="https://aclanthology.org/2021.findings-acl.136.pdf">
                <papertitle>Few-shot Knowledge Graph-to-Text Generation with Pretrained Language Models</papertitle></a><br>
              <i><strong>Junyi Li</strong></i>,
              <i>Tianyi Tang</i>,
	      <i>Wayne Xin Zhao</i>*,
	      <i>Ji-Rong Wen</i>
              <br>
		    <em>Findings of The 59th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2021 <br>
              <a href="https://aclanthology.org/2021.findings-acl.136.pdf">pdf</a>  /  <a href="https://github.com/turboLJY/Few-Shot-KG2Text">code</a> 
            </div>
              <div id="KG-to-Text" style="display:none;text-align:justify">
              This paper studies how to automatically generate a natural language text that describes facts in knowledge graph (KG). 
		      Considering a fewshot setting, we leverage the excellent capacities of pretrained language models (PLMs) in
		      language understanding and generation. We introduce three major technical contributions, namely representation 
		      alignment for bridging the semantic gap between KG encodings and PLMs, relation-biased KG linearization for 
		      deriving better input representations, and multitask learning for learning the correspondence between KG and text. 
		      Extensive experiments on three benchmarks have demonstrated the effectiveness of our model on KG-to-text generation task. 
		      In particular, our model outperforms existing systems on most few-shot settings.
              </div><br>
		
	    <div onmouseover="document.getElementById('PLM-Survey').style.display = 'block';"onmouseout="document.getElementById('PLM-Survey').style.display='none';">
              <a href="https://arxiv.org/pdf/2105.10311.pdf">
                <papertitle>Pretrained Language Model for Text Generation: A Survey</papertitle></a><br>
              <i><strong>Junyi Li</strong></i>&dagger;,
              <i>Tianyi Tang</i>&dagger;,
	      <i>Wayne Xin Zhao</i>*,
	      <i>Ji-Rong Wen</i>
              <br>
		    <em>The 30th International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2021, Survey Track <br>
              <a href="https://arxiv.org/pdf/2105.10311.pdf">pdf</a>   
            </div>
              <div id="PLM-Survey" style="display:none;text-align:justify">
              Text generation has become one of the most important yet challenging tasks in natural language
		processing (NLP). The resurgence of deep learning has greatly advanced this field by neural generation models, especially the paradigm of pretrained language models (PLMs). In this paper,
		we presents an overview of the major advances
		achieved in the topic of PLM for text generation.
		As the preliminaries, we present the general task
		definition and briefly describe the mainstream architectures of PLMs. As the core content, we discuss how to adapt existing PLMs to model different
		input data and satisfy the properties in the generated text. We further summarize several important
		fine-tuning strategies for text generation. Finally,
		we present several future directions and conclude
		this paper. Our survey aims to provide text generation researchers a synthesis and pointer to relatedresearch.
              </div><br>
		
	    <div onmouseover="document.getElementById('KG-Coherence').style.display = 'block';"onmouseout="document.getElementById('KG-Coherence').style.display='none';">
              <a href="https://arxiv.org/pdf/2105.03815.pdf">
		      <papertitle>Knowledge-based Review Generation by Coherence Enhanced Text Planning</papertitle></a><br>
              <i><strong>Junyi Li</strong></i>,
              <i>Wayne Xin Zhao</i>*,
              <i>Zhicheng Wei</i>,
	      <i>Nicholas Jing Yuan</i>,
	      <i>Ji-Rong Wen</i>
              <br>
		<em>The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</em>, 2021 <br>
              <a href="https://arxiv.org/pdf/2105.03815.pdf">pdf</a>  /  <a href="https://github.com/turboLJY/Coherence-Review-Generation">code</a> 
            </div>
              <div id="KG-Coherence" style="display:none;text-align:justify">
		  As a natural language generation task, it is challenging to generate informative and coherent review text. In order to enhance
			the informativeness of the generated text, existing solutions typically learn to copy entities or triples from knowledge graphs (KGs).
			However, they lack overall consideration to select and arrange the
			incorporated knowledge, which tends to cause text incoherence. <br>
		&emsp;To address the above issue, we focus on improving entity-centric
			coherence of the generated reviews by leveraging the semantic structure of KGs. In this paper, we propose a novel Coherence Enhanced
			Text Planning model (CETP) based on knowledge graphs (KGs) to
			improve both global and local coherence for review generation. The
			proposed model learns a two-level text plan for generating a document: (1) the document plan is modeled as a sequence of sentence
			plans in order, and (2) the sentence plan is modeled as an entitybased subgraph from KG. Local coherence can be naturally enforced
			by KG subgraphs through intra-sentence correlations between entities. For global coherence, we design a hierarchical self-attentive
			architecture with both subgraph- and node-level attention to enhance the correlations between subgraphs. To our knowledge, we
			are the first to utilize a KG-based text planning model to enhance
			text coherence for review generation. Extensive experiments on
			three datasets confirm the effectiveness of our model on improving
			the content coherence of generated texts.
              </div><br>
		
	    <heading2><i>2020</i></heading2><br><br>
		
	      <div onmouseover="document.getElementById('KG-Review').style.display = 'block';"onmouseout="document.getElementById('KG-Review').style.display='none';">
              <a href="https://arxiv.org/pdf/2010.01480.pdf">
                <papertitle>Knowledge-Enhanced Personalized Review Generation with Capsule Graph Neural Network</papertitle></a><br>
              <i><strong>Junyi Li</strong></i>,
              <i>Siqing Li</i>,
              <i>Wayne Xin Zhao</i>*,
              <i>Gaole He</i>,
		<i>Zhicheng Wei</i>,
		 <i>Nicholas Jing Yuan</i>,
	      <i>Ji-Rong Wen</i>
              <br>
              <em>The 29th ACM International Conference on Information and Knowledge Management (CIKM)</em>, 2020 <br>
              <a href="https://arxiv.org/pdf/2010.01480.pdf">pdf</a>  /  <a href="https://github.com/turboLJY/CapsGNN-Review-Generation">code</a> 
            </div>
              <div id="KG-Review" style="display:none;text-align:justify">
              Personalized review generation (PRG) aims to automatically produce review text reflecting user preference, which is a challenging
		natural language generation task. Most of previous studies do not
		explicitly model factual description of products, tending to generate
		uninformative content. Moreover, they mainly focus on word-level
		generation, but cannot accurately reflect more abstractive user
		preference in multiple aspects. <br>
		&emsp;To address the above issues, we propose a novel knowledgeenhanced PRG model based on capsule graph neural network (CapsGNN). We first construct a heterogeneous knowledge graph (HKG)
		for utilizing rich item attributes. We adopt Caps-GNN to learn
		graph capsules for encoding underlying characteristics from the
		HKG. Our generation process contains two major steps, namely
		aspect sequence generation and sentence generation. First, based
		on graph capsules, we adaptively learn aspect capsules for inferring the aspect sequence. Then, conditioned on the inferred aspect
		label, we design a graph-based copy mechanism to generate sentences by incorporating related entities or words from HKG. To
		our knowledge, we are the first to utilize knowledge graph for the
		PRG task. The incorporated KG information is able to enhance user
		preference at both aspect and word levels. Extensive experiments
		on three real-world datasets have demonstrated the effectiveness
		of our model on the PRG task.

              </div><br>
			
	      <div onmouseover="document.getElementById('GAN-KGC').style.display = 'block';"onmouseout="document.getElementById('GAN-KGC').style.display='none';">
              <a href="https://arxiv.org/pdf/2003.12718.pdf">
                <papertitle>Mining Implicit Entity Preference from User-Item Interaction Data for Knowledge Graph Completion via Adversarial Learning</papertitle></a><br>
              <i>Gaole He</i>,
              <i><strong>Junyi Li</strong></i>,
              <i>Wayne Xin Zhao</i>*,
              <i>Peiju Liu</i>,
			  <i>Ji-Rong Wen</i>
              <br>
              <em>International World Wide Web Conference (WWW)</em>, 2020 <br>
              <a href="https://arxiv.org/pdf/2003.12718.pdf">pdf</a>  /  <a href="https://github.com/RUCAIBox/UPGAN">code</a> 
            </div>
              <div id="GAN-KGC" style="display:none;text-align:justify">
              The task of Knowledge Graph Completion (KGC) aims to automatically infer the missing fact information in Knowledge Graph (KG).In this paper, we take a new perspective that aims to leverage rich
				user-item interaction data (user interaction data for short) for improving the KGC task. Our work is inspired by the observation that
				many KG entities correspond to online items in application systems.
				However, the two kinds of data sources have very different intrinsic
				characteristics, and it is likely to hurt the original representation
				performance using simple fusion strategy. <br>
				&emsp;To address this challenge, we propose a novel adversarial learning approach for leveraging user interaction data for the KGC task.
				Our generator is isolated from user interaction data, and improves
				itself according to the feedback from the discriminator. The discriminator takes the learned useful information from user interaction
				data as input, and gradually enhances the evaluation capacity in
				order to identify the fake samples generated by the generator. To
				discover implicit entity preference of users, we design an elaborate
				collaborative learning algorithms based on graph neural networks,
				which will be jointly optimized with the discriminator. Such an
				approach is effective to alleviate the issues about data heterogeneity
				and semantic complexity for the KGC task. Extensive experiments
				on three real-world datasets have demonstrated the effectiveness
				of our approach on the KGC task.

              </div><br>
		

            <heading2><i>2019</i></heading2><br><br>

            <div onmouseover="document.getElementById('ACF').style.display = 'block';"
                onmouseout="document.getElementById('ACF').style.display='none';">
              <a href="https://www.aclweb.org/anthology/P19-1190.pdf">
                <papertitle>Generating Long and Informative Reviews with Aspect-Aware Coarse-to-Fine Decoding</papertitle></a><br>
              <i><strong>Junyi Li</strong></i>,
              <i>Wayne Xin Zhao</i>*,
			  <i>Ji-Rong Wen</i>,
			  <i>Yang Song</i>
              <br>
              <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2019 <br>
              <a href="https://www.aclweb.org/anthology/P19-1190.pdf">pdf</a>  /  <a href="https://github.com/turboLJY/Coarse-to-Fine-Review-Generation">code</a> 
            </div>
              <div id="ACF" style="display:none;text-align:justify">
              Generating long and informative review text
				is a challenging natural language generation
				task. Previous work focuses on word-level
				generation, neglecting the importance of topical and syntactic characteristics from natural
				languages. In this paper, we propose a novel
				review generation model by characterizing an
				elaborately designed aspect-aware coarse-tofine generation process. First, we model the
				aspect transitions to capture the overall content
				flow. Then, to generate a sentence, an aspectaware sketch will be predicted using an aspectaware decoder. Finally, another decoder fills in
				the semantic slots by generating corresponding words. Our approach is able to jointly
				utilize aspect semantics, syntactic sketch, and
				context information. Extensive experiments
				results have demonstrated the effectiveness of
				the proposed model.
              </div><br>
              * Corresponding author <br>
	      &dagger; Equal contribution
        </td></tr>
		
	<tr><td width="100%" valign="middle">
            <heading>Open Source Projects</heading> <br><br>
		(Most of my research work are open-source. Here are some my preferable projects!)
		<ul>
		<li><a href="https://github.com/RUCAIBox/TextBox" target="_black">TextBox</a><br>A unified, comprehensive and efficient framework for reproducing and developing 
			text generation algorithms, covering more than 20 base models and nearly 10 benchmarks.</li>
		</ul>
	</td></tr>
		
	<tr><td width="100%" valign="middle">
            <heading>Professional Services</heading> <br><br>
			<ul>
			<li>Reviewer
				<ul>
					<li>Journal: TALLIP</li>
					<li>Conference: AAAI 2021, IJCAI 2021, KDD 2021</li>
				</ul>
			</li>
			<li>Chair
				<ul>
					<li>CSSNLP 2020 (Co-Chair)</li>
				</ul>
			</li>
			</ul>
	</td></tr>
		
	<tr><td width="100%" valign="middle">
            <heading>Selected Awards and Honors</heading> <br><br>
			<ul>
			<li>SIGIR Student Travel Grant (CIKM 2020)</li>
			<li>National Scholarship for Graduate Student (top 2% students), Ministry of Education of P.R.China, 2019</li>
			<li>China Undergraduate Mathematical Contest in Modeling, Second Prize in Beijing Contest District, 2016</li>	
			</ul>
	</td></tr>
		
	<tr><td width="100%" valign="middle">
            <heading>Education</heading> <br><br>
			<ul>
			<li>Ph.D. student of Artificial Intelligence, Renmin University of China, 2020-present
			</li>
			<li>M.Sc. of Computer Application, Renmin University of China, 2018-2020
			</li>
			<li>B.Sc. of Computer Science, Renmin University of China, 2014-2018
			</li>
			</ul>
	</td></tr>
		
	<tr><td width="100%" valign="middle">
            <heading>Miscellaneous</heading> <br><br>
		<p>
		  <a href="https://en.wikipedia.org/wiki/Liu_Haoran">Who?</a> My idol. Haoran brings me happiness during my life. He just likes "fill in the blanks of my life".
		</p>
			
	</td></tr><br>
		
	<tr><td width="100%" valign="middle">
	<center>
	<script type="text/javascript" src="//rf.revolvermaps.com/0/0/1.js?i=571ds4qroi6&amp;s=220&amp;m=7&amp;v=true&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000" async="async"></script>
	</center>
	</td></tr>
		
	</tbody></table>
	   
	
	<script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-59618557-1', 'auto');
                ga('send', 'pageview');

              </script>

    </td>
    </tr>
  </tbody></table>
  
  <!--footer start-->
 <footer class="footer">
	<p>Copyright 2021. All Rights Reserved by Junyi Li.</p>
 </footer>
     <!--footer end-->
  
</body></html>
